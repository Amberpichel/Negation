{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "METRICS: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negated      0.383     0.756     0.508        41\n",
      "    Negation      1.000     1.000     1.000         1\n",
      "  NotNegated      0.982     0.918     0.949       609\n",
      "\n",
      "    accuracy                          0.908       651\n",
      "   macro avg      0.788     0.891     0.819       651\n",
      "weighted avg      0.945     0.908     0.921       651\n",
      "\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.svm import SVC\n",
    "import csv\n",
    "from csv import writer\n",
    "from csv import reader\n",
    "import gensim\n",
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def extract_features_and_labels(trainingfile):\n",
    "    \"\"\"Extract features from trainingdata\n",
    "    Extract labels from trainingdata\"\"\"\n",
    "    \n",
    "    data = []\n",
    "    targets = []\n",
    "    with open(trainingfile, 'r', encoding='utf8') as infile:\n",
    "        for line in infile:\n",
    "            components = line.rstrip('\\n').split()\n",
    "            if len(components) > 0:\n",
    "                offsetword = components[0]\n",
    "                prev_tokens_one = components[1]\n",
    "                prev_tokens_two = components[2]\n",
    "                prev_tokens_three = components[3]\n",
    "                prev_tokens_four = components[4]\n",
    "                next_tokens_one = components[5]\n",
    "                next_tokens_two = components[6]\n",
    "                next_tokens_three = components[7]\n",
    "                pos_prev_one = components[7]\n",
    "                pos_prev_two = components[8]\n",
    "                pos_prev_three = components[9]\n",
    "                pos_prev_four = components[10]\n",
    "                pos_next_one = components[11]\n",
    "                pos_next_two = components[12]\n",
    "                pos_next_three = components[13]\n",
    "                neg_prev_one = components[14]\n",
    "                neg_prev_two = components[15]\n",
    "                neg_prev_three = components[16]\n",
    "                neg_prev_four = components[17]\n",
    "                neg_next_one = components[18]\n",
    "                neg_next_two = components[19]\n",
    "                neg_next_three = components[20]\n",
    "                neg = components[21]\n",
    "                \n",
    "                feature_dict = {'Event': offsetword,\n",
    "                                'Previous token one': prev_tokens_one[0],\n",
    "                                'Previous token two': prev_tokens_two[0],\n",
    "                                'Previous token three': prev_tokens_three[0],\n",
    "                                'Previous token four': prev_tokens_four[0],\n",
    "                                'Next token one': next_tokens_one[0],\n",
    "                                'Next token two': next_tokens_two[0],\n",
    "                                'Next token three': next_tokens_three[0],\n",
    "                                'POS previous token one': pos_prev_one[0],\n",
    "                                'POS previous token two': pos_prev_two[0],\n",
    "                                'POS previous token three': pos_prev_three[0],\n",
    "                                'POS previous token four': pos_prev_four[0],\n",
    "                                'POS next token one': pos_next_one[0],\n",
    "                                'POS next token two': pos_next_two[0],\n",
    "                                'POS next token three': pos_next_three[0],\n",
    "                                'Negcue prev token one': neg_prev_one[0],\n",
    "                                'Negcue prev token two': neg_prev_two[0],\n",
    "                                'Negcue prev token three': neg_prev_three[0],\n",
    "                                'Negcue prev token four': neg_prev_four[0],\n",
    "                                'Negcue next token one': neg_next_one[0],\n",
    "                                'Negcue next token two': neg_next_two[0],\n",
    "                                'Negcue next token three': neg_next_three[0],\n",
    "                                'Negation': neg}\n",
    "                data.append(feature_dict)\n",
    "                targets.append(components[-1])\n",
    "    return data, targets\n",
    "\n",
    "def create_classifier(train_features, train_targets, modelname):\n",
    "    \"\"\"Create classifier, feed it with the training features and labels\"\"\"   \n",
    "    \n",
    "    modelname == 'SVM'\n",
    "    model = SVC()\n",
    "    vec = DictVectorizer()\n",
    "    features_vectorized = vec.fit_transform(train_features)#.toarray()\n",
    "    model.fit(features_vectorized, train_targets)\n",
    "    \n",
    "    return model, vec\n",
    "\n",
    "def get_predicted_and_gold_labels(model, vec, inputdata): #outputfile):\n",
    "    \"\"\"Make predictions from the test data and write it to an outputfile\"\"\"  \n",
    "\n",
    "    features, gold_labels = extract_features_and_labels(inputdata)\n",
    "    features = vec.transform(features)\n",
    "    predictions = model.predict(features)\n",
    "\n",
    "    return gold_labels, predictions\n",
    "\n",
    "def print_confusion_matrix(predictions, goldlabels):\n",
    "    '''\n",
    "    Function that prints out a confusion matrix\n",
    "    :param predictions: predicted labels\n",
    "    :param goldlabels: gold standard labels\n",
    "    :type predictions, goldlabels: list of strings\n",
    "    :returns: confusion matrix\n",
    "    '''\n",
    "\n",
    "    # based on example from https://datatofish.com/confusion-matrix-python/\n",
    "    data = {'Gold': goldlabels, 'Predicted': predictions}\n",
    "    df = pd.DataFrame(data, columns=['Gold', 'Predicted'])\n",
    "\n",
    "    confusion_matrix = pd.crosstab(df['Gold'], df['Predicted'], rownames=['Gold'], colnames=['Predicted'])\n",
    "    print(confusion_matrix)\n",
    "    \n",
    "    return confusion_matrix\n",
    "\n",
    "\n",
    "def print_precision_recall_fscore(predictions, goldlabels):\n",
    "    '''\n",
    "    Function that prints out precision, recall and f-score in a complete report\n",
    "    :param predictions: predicted output by classifier\n",
    "    :param goldlabels: original gold labels\n",
    "    :type predictions, goldlabels: list of strings\n",
    "    '''\n",
    "\n",
    "    report = classification_report(goldlabels,predictions,digits = 3)\n",
    "\n",
    "    print('METRICS: ')\n",
    "    print()\n",
    "    print(report)\n",
    "\n",
    "    \n",
    "def main(argv=None):\n",
    "    \"\"\"Run all the above functions\"\"\"    \n",
    "\n",
    "    trainingfile = 'train.tsv'\n",
    "    inputfile = 'test.tsv'\n",
    "    outputfile = 'outputfile' + '.tsv'\n",
    "    \n",
    "    training_features, gold_labels = extract_features_and_labels(trainingfile)\n",
    "    for modelname in ['SVM']:\n",
    "        ml_model, vec = create_classifier(training_features, gold_labels, modelname)\n",
    "        predictions, goldlabels = get_predicted_and_gold_labels(ml_model, vec, inputfile)\n",
    "        #classify_data(ml_model, vec, inputfile)#, outputfile.replace('.tsv','.' + modelname + '.tsv'), data[-1])\n",
    "        print()\n",
    "        #print('---->'+ modelname + ' with ' + ' and '.join(selected_features) + ' as features <----')\n",
    "        print_precision_recall_fscore(predictions, goldlabels)\n",
    "        print('------')\n",
    "        \n",
    "        outfile = open(outputfile, 'w')\n",
    "        counter = 0\n",
    "        for line in open(inputfile, 'r'):\n",
    "            if len(line.rstrip('\\n').split()) > 0:\n",
    "                outfile.write(line.rstrip('\\n') + '\\t' + predictions[counter] + '\\n')\n",
    "                counter += 1\n",
    "        outfile.close()\n",
    "    \n",
    "#    return predictions\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
